{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El array de predicciones para los casos de prueba es: \n",
      "[0 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ernie\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:197: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid broadcasting comparison [array([0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n       0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1], dtype=int64)] with block values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-1b87f6ad165d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;31m#Calcula porcentaje de aciertos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m \u001b[0maciertos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicciones\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nEl porcentaje de aciertos de la prediccion para los casos de prueba de la red neuronal de 3 capas tras el entreno de sus pesos para landa = \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" y \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iteraciones\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" iteraciones es: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maciertos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" %.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1302\u001b[0m             \u001b[1;31m# straight boolean comparisions we want to allow all columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m             \u001b[1;31m# (regardless of dtype to pass thru) See #4537 for discussion.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_combine_const\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1305\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_combine_const\u001b[1;34m(self, other, func, raise_on_error)\u001b[0m\n\u001b[0;32m   3541\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_combine_const\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3542\u001b[0m         new_data = self._data.eval(func=func, other=other,\n\u001b[1;32m-> 3543\u001b[1;33m                                    raise_on_error=raise_on_error)\n\u001b[0m\u001b[0;32m   3544\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   3195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3196\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3197\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'eval'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3199\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mquantile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m   3089\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3090\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mgr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3091\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3092\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3093\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, func, other, raise_on_error, try_cast, mgr)\u001b[0m\n\u001b[0;32m   1200\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m                     raise ValueError('Invalid broadcasting comparison [%s] '\n\u001b[1;32m-> 1202\u001b[1;33m                                      'with block values' % repr(other))\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m                 raise TypeError('Could not compare [%s] with block values' %\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid broadcasting comparison [array([0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n       0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1], dtype=int64)] with block values"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.parsers import read_csv\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy . optimize as opt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def carga_csv(filename) :\n",
    "    valores = read_csv(filename, header=None).values\n",
    "    return valores\n",
    "\n",
    "datos = carga_csv(\"Data/wdbc.csv\")\n",
    "X = datos[:, 2:32]\n",
    "X = X.astype(float)\n",
    "\n",
    "y = datos[:, 1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def gradSigmoide(z):\n",
    "    return np.multiply(sigmoid(z), 1-sigmoid(z))\n",
    "\n",
    "def hipotesis(comp, x):\n",
    "    return sigmoid(x.dot(comp))\n",
    "\n",
    "def pesosAleatorios(L_in, L_out, ini):\n",
    "    return np.random.rand(L_out, 1+L_in) * 2 * ini - ini\n",
    "\n",
    "def gradiente(theta1, theta2, X, y, reg):\n",
    "    delta1 = np.zeros(theta1.shape)\n",
    "    delta2 = np.zeros(theta2.shape)\n",
    "    m = len(y)\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        ones = np.ones(1)\n",
    "        a1 = np.hstack((ones, X[i]))\n",
    "        z2 = a1 @ theta1.T\n",
    "        a2 = np.hstack((ones, sigmoid(z2)))\n",
    "        z3 = a2 @ theta2.T\n",
    "        a3 = sigmoid(z3)\n",
    "\n",
    "        error3 = a3 - y.iloc[i,:][np.newaxis,:]\n",
    "        z2 = np.hstack((ones, z2))\n",
    "        error2 = np.multiply(theta2.T @ error3.T, gradSigmoide(z2).T[:,np.newaxis])\n",
    "        delta1 = delta1 + error2[1:,:] @ a1[np.newaxis,:]\n",
    "        delta2 = delta2 + error3.T @ a2[np.newaxis,:]\n",
    "        \n",
    "    delta1 = delta1 / m\n",
    "    delta2 = delta2 / m\n",
    "    \n",
    "    delta1[:,1:] = delta1[:,1:] + theta1[:,1:] * reg / m\n",
    "    delta2[:,1:] = delta2[:,1:] + theta2[:,1:] * reg / m\n",
    "        \n",
    "    return np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
    "\n",
    "def funcionCoste(theta1, theta2, X, y, landa, num_etiquetas):\n",
    "    h = propagacion(X, theta1, theta2)\n",
    "    m = len(y)\n",
    "    \n",
    "    matriz1 = np.multiply(y, np.log(h))\n",
    "    \n",
    "    matriz2 = np.multiply(1-y, np.log(1-h))\n",
    "    \n",
    "    matriz3 = np.sum(matriz1 + matriz2)\n",
    "    \n",
    "    primerSumatorio = np.sum(np.sum(np.power(theta1[:,1:],2), axis = 1))\n",
    "    segundoSumatotrio = np.sum(np.sum(np.power(theta2[:,1:],2), axis = 1))\n",
    "    regularizacion = (primerSumatorio + segundoSumatotrio) * landa/(2*m)\n",
    "    \n",
    "    return np.sum(matriz3 / (-m)) + regularizacion\n",
    "    \n",
    "def backprop (params_rn ,num_entradas ,num_ocultas ,num_etiquetas ,X,y ,reg ):\n",
    "    y_d = pd.get_dummies(y.flatten())   \n",
    "    \n",
    "    theta1 = np.reshape(params_rn[:num_ocultas * (num_entradas+1)] ,(num_ocultas,(num_entradas + 1)))\n",
    "    theta2 = np.reshape(params_rn[num_ocultas * (num_entradas + 1):],( num_etiquetas, (num_ocultas + 1)))\n",
    "    \n",
    "    \n",
    "    Z = funcionCoste(theta1, theta2, X, y_d, reg, 10)   #Calcula coste\n",
    "    grad = gradiente(theta1, theta2, X, y_d, reg)       #Calcula gradiente\n",
    "    return Z, grad\n",
    "\n",
    "\n",
    "def propagacion(X, theta1, theta2):  #FeedForward\n",
    "    X = np.c_[np.ones((len(X),1)),X]\n",
    "    capa1 = hipotesis(theta1.T, X)\n",
    "    capa1 = np.c_[np.ones((len(capa1),1)),capa1]\n",
    "    salida = hipotesis(theta2.T, capa1)\n",
    "    return salida\n",
    "\n",
    "def seleccionLanda(X_train, X_test, y_train, y_test, landa):\n",
    "    num_entradas = 30\n",
    "    num_ocultas = 2   #25\n",
    "    num_etiquetas = 2\n",
    "    num_iteraciones = 200\n",
    "    epsilon = 0.12\n",
    "\n",
    "    #Inicializar pesos con el valor de epsilon\n",
    "    theta1 = pesosAleatorios(num_entradas, num_ocultas,epsilon)\n",
    "    theta2 = pesosAleatorios(num_ocultas, num_etiquetas, epsilon)\n",
    "\n",
    "    #Roll de los pesos iniciales\n",
    "    params_rn = np.concatenate((np.ravel(theta1), np.ravel(theta2)))\n",
    "    \n",
    "    costeEnt  = np.zeros(len(landa))\n",
    "    costeVal = np.zeros(len(landa))\n",
    "        \n",
    "    \n",
    "    for i in range(len(landa)):\n",
    "        cost, grad = backprop (params_rn ,num_entradas ,num_ocultas ,num_etiquetas ,X_train,y_train,landa[i])\n",
    "        theta_opt = opt.minimize(fun=backprop, x0=params_rn, args=(num_entradas, num_ocultas, num_etiquetas, X_train, y_train, landa[i]), method='TNC', jac=True, options={'maxiter': num_iteraciones})\n",
    "\n",
    "        #Unroll de los pesos optimos\n",
    "        theta1_opt = np.reshape(theta_opt.x[:num_ocultas * (num_entradas+1)] ,(num_ocultas,(num_entradas + 1)))\n",
    "        theta2_opt = np.reshape(theta_opt.x[num_ocultas * (num_entradas + 1):],( num_etiquetas, (num_ocultas + 1)))\n",
    "        \n",
    "        output = propagacion(X,theta1_opt, theta2_opt)\n",
    "        predicciones = output.argmax(axis=1)\n",
    "        y_cost = np.array(y_train == 'M').astype(int)\n",
    "        costeEnt[i] = np.mean(predicciones == y_cost.flatten()) * 100\n",
    "        \n",
    "        output = propagacion(X_test,theta1_opt, theta2_opt)\n",
    "        predicciones = output.argmax(axis=1)\n",
    "        y_test = np.array(y_test == 'M').astype(int)\n",
    "        costeVal[i] = np.mean(predicciones == y_test.flatten()) * 100\n",
    "        \n",
    "        \n",
    "        \n",
    "    plt.figure()\n",
    "    plt.plot(landa, costeEnt, '-', c = \"C1\")\n",
    "    plt.plot(landa, costeVal,'-',c=\"b\")\n",
    "    \n",
    "    plt.legend(['Entrenamiento', 'Validacion'])\n",
    "    plt.title('Seleccion de landa')\n",
    "    plt.xlabel('Landa')\n",
    "    plt.ylabel('Error')\n",
    "    \n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,10])\n",
    "    axes.set_ylim([0,50])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "#Inicializar parametros de la red neuronal\n",
    "num_entradas = 30\n",
    "num_ocultas = 2   #25\n",
    "num_etiquetas = 2\n",
    "reg = 1\n",
    "num_iteraciones = 200\n",
    "\n",
    "epsilon = 0.12\n",
    "\n",
    "#Inicializar pesos con el valor de epsilon\n",
    "theta1 = pesosAleatorios(num_entradas, num_ocultas,epsilon)\n",
    "theta2 = pesosAleatorios(num_ocultas, num_etiquetas, epsilon)\n",
    "\n",
    "#Roll de los pesos iniciales\n",
    "params_rn = np.concatenate((np.ravel(theta1), np.ravel(theta2)))\n",
    "\n",
    "#Obtener coste y gradiente para los pesos iniciales\n",
    "cost, grad = backprop (params_rn ,num_entradas ,num_ocultas ,num_etiquetas ,X_train,y_train,reg)\n",
    "\n",
    "#Minimizar la funcion coste con el gradiente calculado para obtener los pesos optimos\n",
    "theta_opt = opt.minimize(fun=backprop, x0=params_rn, args=(num_entradas, num_ocultas, num_etiquetas, X_train, y_train, reg), method='TNC', jac=True, options={'maxiter': num_iteraciones})\n",
    "\n",
    "#Unroll de los pesos optimos\n",
    "theta1_opt = np.reshape(theta_opt.x[:num_ocultas * (num_entradas+1)] ,(num_ocultas,(num_entradas + 1)))\n",
    "theta2_opt = np.reshape(theta_opt.x[num_ocultas * (num_entradas + 1):],( num_etiquetas, (num_ocultas + 1)))\n",
    "\n",
    "#Calcula la salida de la red para los datos X con los pesos optimos \n",
    "output = propagacion(X_test,theta1_opt, theta2_opt)\n",
    "\n",
    "#Hallar la prediccion para cada ejemplo:\n",
    "\n",
    "predicciones = output.argmax(axis=1)\n",
    "#predicciones = predicciones\n",
    "\n",
    "print(\"El array de predicciones para los casos de prueba es: \\n\" + str(predicciones))\n",
    "\n",
    "landa_sel = np.array([0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10])\n",
    "#seleccionLanda(X_train, X_test, y_train, y_test, landa_sel)\n",
    "\n",
    "y_test = np.array(y_test == 'M').astype(int)\n",
    "\n",
    "#Calcula porcentaje de aciertos\n",
    "aciertos = np.mean(predicciones == y_test.flatten()) * 100\n",
    "print(\"\\nEl porcentaje de aciertos de la prediccion para los casos de prueba de la red neuronal de 3 capas tras el entreno de sus pesos para landa = \" + str(reg) + \" y \" + str(num_iteraciones) + \" iteraciones es: \" + str(aciertos)+\" %.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
