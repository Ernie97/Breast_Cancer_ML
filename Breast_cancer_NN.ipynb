{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El array de predicciones para los casos de prueba es: \n",
      "[0 1 1 1 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1\n",
      " 1 1 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1]\n",
      "\n",
      "El porcentaje de aciertos de la prediccion para los casos de prueba de la red neuronal de 3 capas tras el entreno de sus pesos para landa = 1 y 200 iteraciones es: 95.1048951048951 %.\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.parsers import read_csv\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy . optimize as opt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def carga_csv(filename) :\n",
    "    valores = read_csv(filename, header=None).values\n",
    "    return valores\n",
    "\n",
    "datos = carga_csv(\"Data/wdbc.csv\")\n",
    "X = datos[:, 2:32]\n",
    "X = X.astype(float)\n",
    "\n",
    "y = datos[:, 1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def gradSigmoide(z):\n",
    "    return np.multiply(sigmoid(z), 1-sigmoid(z))\n",
    "\n",
    "def hipotesis(comp, x):\n",
    "    return sigmoid(x.dot(comp))\n",
    "\n",
    "def pesosAleatorios(L_in, L_out, ini):\n",
    "    return np.random.rand(L_out, 1+L_in) * 2 * ini - ini\n",
    "\n",
    "def gradiente(theta1, theta2, X, y, reg):\n",
    "    delta1 = np.zeros(theta1.shape)\n",
    "    delta2 = np.zeros(theta2.shape)\n",
    "    m = len(y)\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        ones = np.ones(1)\n",
    "        a1 = np.hstack((ones, X[i]))\n",
    "        z2 = a1 @ theta1.T\n",
    "        a2 = np.hstack((ones, sigmoid(z2)))\n",
    "        z3 = a2 @ theta2.T\n",
    "        a3 = sigmoid(z3)\n",
    "\n",
    "        error3 = a3 - y.iloc[i,:][np.newaxis,:]\n",
    "        z2 = np.hstack((ones, z2))\n",
    "        error2 = np.multiply(theta2.T @ error3.T, gradSigmoide(z2).T[:,np.newaxis])\n",
    "        delta1 = delta1 + error2[1:,:] @ a1[np.newaxis,:]\n",
    "        delta2 = delta2 + error3.T @ a2[np.newaxis,:]\n",
    "        \n",
    "    delta1 = delta1 / m\n",
    "    delta2 = delta2 / m\n",
    "    \n",
    "    delta1[:,1:] = delta1[:,1:] + theta1[:,1:] * reg / m\n",
    "    delta2[:,1:] = delta2[:,1:] + theta2[:,1:] * reg / m\n",
    "        \n",
    "    return np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
    "\n",
    "def funcionCoste(theta1, theta2, X, y, landa, num_etiquetas):\n",
    "    h = propagacion(X, theta1, theta2)\n",
    "    m = len(y)\n",
    "    \n",
    "    matriz1 = np.multiply(y, np.log(h))\n",
    "    \n",
    "    matriz2 = np.multiply(1-y, np.log(1-h))\n",
    "    \n",
    "    matriz3 = np.sum(matriz1 + matriz2)\n",
    "    \n",
    "    primerSumatorio = np.sum(np.sum(np.power(theta1[:,1:],2), axis = 1))\n",
    "    segundoSumatotrio = np.sum(np.sum(np.power(theta2[:,1:],2), axis = 1))\n",
    "    regularizacion = (primerSumatorio + segundoSumatotrio) * landa/(2*m)\n",
    "    \n",
    "    return np.sum(matriz3 / (-m)) + regularizacion\n",
    "    \n",
    "def backprop (params_rn ,num_entradas ,num_ocultas ,num_etiquetas ,X,y ,reg ):\n",
    "    y_d = pd.get_dummies(y.flatten())   \n",
    "    \n",
    "    theta1 = np.reshape(params_rn[:num_ocultas * (num_entradas+1)] ,(num_ocultas,(num_entradas + 1)))\n",
    "    theta2 = np.reshape(params_rn[num_ocultas * (num_entradas + 1):],( num_etiquetas, (num_ocultas + 1)))\n",
    "    \n",
    "    \n",
    "    Z = funcionCoste(theta1, theta2, X, y_d, reg, 10)   #Calcula coste\n",
    "    grad = gradiente(theta1, theta2, X, y_d, reg)       #Calcula gradiente\n",
    "    return Z, grad\n",
    "\n",
    "\n",
    "def propagacion(X, theta1, theta2):  #FeedForward\n",
    "    X = np.c_[np.ones((len(X),1)),X]\n",
    "    capa1 = hipotesis(theta1.T, X)\n",
    "    capa1 = np.c_[np.ones((len(capa1),1)),capa1]\n",
    "    salida = hipotesis(theta2.T, capa1)\n",
    "    return salida\n",
    "\n",
    "    \n",
    "\n",
    "#Inicializar parametros de la red neuronal\n",
    "num_entradas = 30\n",
    "num_ocultas = 2   #25\n",
    "num_etiquetas = 2\n",
    "reg = 1\n",
    "num_iteraciones = 200\n",
    "\n",
    "epsilon = 0.12\n",
    "\n",
    "#Inicializar pesos con el valor de epsilon\n",
    "theta1 = pesosAleatorios(num_entradas, num_ocultas,epsilon)\n",
    "theta2 = pesosAleatorios(num_ocultas, num_etiquetas, epsilon)\n",
    "\n",
    "#Roll de los pesos iniciales\n",
    "params_rn = np.concatenate((np.ravel(theta1), np.ravel(theta2)))\n",
    "\n",
    "#Obtener coste y gradiente para los pesos iniciales\n",
    "cost, grad = backprop (params_rn ,num_entradas ,num_ocultas ,num_etiquetas ,X_train,y_train,reg)\n",
    "\n",
    "#Minimizar la funcion coste con el gradiente calculado para obtener los pesos optimos\n",
    "theta_opt = opt.minimize(fun=backprop, x0=params_rn, args=(num_entradas, num_ocultas, num_etiquetas, X_train, y_train, reg), method='TNC', jac=True, options={'maxiter': num_iteraciones})\n",
    "\n",
    "#Unroll de los pesos optimos\n",
    "theta1_opt = np.reshape(theta_opt.x[:num_ocultas * (num_entradas+1)] ,(num_ocultas,(num_entradas + 1)))\n",
    "theta2_opt = np.reshape(theta_opt.x[num_ocultas * (num_entradas + 1):],( num_etiquetas, (num_ocultas + 1)))\n",
    "\n",
    "#Calcula la salida de la red para los datos X con los pesos optimos \n",
    "output = propagacion(X_test,theta1_opt, theta2_opt)\n",
    "\n",
    "#Hallar la prediccion para cada ejemplo:\n",
    "\n",
    "predicciones = output.argmax(axis=1)\n",
    "#predicciones = predicciones\n",
    "\n",
    "print(\"El array de predicciones para los casos de prueba es: \\n\" + str(predicciones))\n",
    "\n",
    "y_test = np.array(y_test == 'M').astype(int)\n",
    "\n",
    "#Calcula porcentaje de aciertos\n",
    "aciertos = np.mean(predicciones == y_test.flatten()) * 100\n",
    "print(\"\\nEl porcentaje de aciertos de la prediccion para los casos de prueba de la red neuronal de 3 capas tras el entreno de sus pesos para landa = \" + str(reg) + \" y \" + str(num_iteraciones) + \" iteraciones es: \" + str(aciertos)+\" %.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
